---
title: "Exercise №4"
format:
  md:
    output-file: README.md
editor: visual
---

## Цель работы

1. Изучить возможности СУБД DuckDB для обработки и анализ больших данных

2. Получить навыки применения DuckDB совместно с языком программирования R

3. Получить навыки анализа метаинфомации о сетевом трафике

4. Получить навыки применения облачных технологий хранения, подготовки и
анализа данных: Yandex Object Storage, Rstudio Server.

## Исходные данные

1.  ОС Windows
2.  OpenSSH Client
3.  Apache Arrow
4.  RStudio Server
5.  Yandex Object Storage
6.  DuckDB

## Ход работы

### Обеспечение доступа к датасету arrow-datasets/tm_data.pqt

```{r}
library(duckdb)
library(dplyr)
library(tidyverse)

con <- dbConnect(duckdb::duckdb(), dbdir = ":memory:")
dbExecute(conn = con, "INSTALL httpfs; LOAD httpfs;")

PARQUET_FILE1 = "https://storage.yandexcloud.net/arrow-datasets/tm_data.pqt"

```

### Чтение датасета

```{r}
sql <- "SELECT * FROM read_parquet([?])"
raw_df <- dbGetQuery(con, sql, list(PARQUET_FILE1))

raw_df %>% glimpse()
```

### Задание 1

#### Очистка датасета от внутренних обращений. Группировка по уникальным отправителям. Нахождение максимального объема отправленных данных

```{r}
nolegitimate_flow <- raw_df %>% 
  select(src, dst, bytes) %>% 
  filter(!str_detect(dst, '1[2-4].*')) %>% 
  select(src, bytes) %>% group_by(src) %>% summarize(sum_bytes = sum(bytes)) %>% 
  filter(sum_bytes == max(sum_bytes))
nolegitimate_flow |> collect()

```

### Задание 2

```{r}
filter_df <- raw_df %>%
      select(timestamp, src, dst, bytes) %>%
      mutate(external_flow = (str_detect(src, '1[2-4].*') & !str_detect(dst, '1[2-4].*')),time = hour(as_datetime(timestamp/1000))) %>%
      filter(external_flow == TRUE, time >= 0 & time <= 24) %>% group_by(time) %>%
      summarise(flow_time = n()) %>% arrange(desc(flow_time))

filter_df <- filter_df %>% filter(flow_time >= mean(flow_time))

filter_df |> collect()
```

#### После фильтра по времени, определил максимально отправленный объем данных и отправителя

```{r}
answer_df <- raw_df %>% mutate(time = hour(as_datetime(timestamp/1000))) %>% 
  filter(!str_detect(src, "^13.37.84.125")) %>% 
  filter(str_detect(src, '1[2-4].*'))  %>% filter(!str_detect(dst, '1[2-4].*'))  %>%
  filter(time >= 1 & time <= 15) %>% 
  group_by(src) %>% summarise("sum" = sum(bytes)) %>%
  select(src,sum)

answer_df <- answer_df %>% arrange(desc(sum)) %>% head(1)

answer_df |> collect()
```

### Задание 3

#### Поиск необходимого порта

```{r}
filter_df_3 <- raw_df %>% filter(!str_detect(src, "^13.37.84.125")) %>% filter(!str_detect(src, "^12.55.77.96")) %>% 
  filter(str_detect(src, '1[2-4].*'))  %>%
  filter(!str_detect(dst, '1[2-4].*'))  %>% select(src, bytes, port) 


full_df <- filter_df_3 %>%  group_by(port) %>% summarise("mean_bytes"=mean(bytes), "max_bytes"=max(bytes), "sum_bytes" = sum(bytes)) %>% 
  mutate("diff_max_mean"= max_bytes-mean_bytes) %>% arrange(desc(diff_max_mean)) %>% head(1)

full_df |> collect()
```

#### Поиск максимального объема пераданных данных через найденный ранее порт 37 и отправителя

```{r}
answer_df_3 <- filter_df_3  %>% filter(port==37) %>% group_by(src) %>% 
  summarise("mean_bytes"=mean(bytes)) %>% arrange(desc(mean_bytes)) %>% select(src) %>% head(1)
answer_df_3 |> collect()
```

### Выводы

Ознакомился с СУБД DuckDB для обработки и анализ больших данных совместно с языком программирования R